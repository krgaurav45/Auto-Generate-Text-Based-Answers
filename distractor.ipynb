{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WgwFnXdSREYm"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "jH1VvkINfaQ6",
    "outputId": "3e21ef8a-3e5b-4905-9494-a51ef4378cea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter \n",
    "from nltk.corpus import wordnet # To get words in dictionary with their parts of speech\n",
    "from nltk.stem import WordNetLemmatizer # lemmatizes word based on it's parts of speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-BhwRlWtW6f"
   },
   "source": [
    "**Importing Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "fEuO241fiL0b",
    "outputId": "4b2ae7b2-fe4f-4288-d06b-452aa349a7e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>distractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meals can be served</td>\n",
       "      <td>in rooms at 9:00 p. m.</td>\n",
       "      <td>'outside the room at 3:00 p. m.', 'in the dini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It can be inferred from the passage that</td>\n",
       "      <td>The local government can deal with the problem...</td>\n",
       "      <td>'If some tragedies occur again ', ' relevant d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The author called Tommy 's parents in order to</td>\n",
       "      <td>help them realize their influence on Tommy</td>\n",
       "      <td>'blame Tommy for his failing grades', 'blame T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It can be inferred from the passage that</td>\n",
       "      <td>the writer is not very willing to use idioms</td>\n",
       "      <td>'idioms are the most important part in a langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can we deal with snake wounds according to...</td>\n",
       "      <td>Stay calm and do n't move .</td>\n",
       "      <td>'Cut the wound and suck the poison out .'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  ...                                         distractor\n",
       "0                                Meals can be served  ...  'outside the room at 3:00 p. m.', 'in the dini...\n",
       "1           It can be inferred from the passage that  ...  'If some tragedies occur again ', ' relevant d...\n",
       "2     The author called Tommy 's parents in order to  ...  'blame Tommy for his failing grades', 'blame T...\n",
       "3           It can be inferred from the passage that  ...  'idioms are the most important part in a langu...\n",
       "4  How can we deal with snake wounds according to...  ...          'Cut the wound and suck the poison out .'\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('/content/drive/My Drive/VL_DATA/Train.csv')\n",
    "df_test = pd.read_csv('/content/drive/My Drive/VL_DATA/Test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ei9_o9NDubtT"
   },
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IeGsmBhEuh0i"
   },
   "source": [
    "Conversion of text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PbRLsNfiTO3"
   },
   "outputs": [],
   "source": [
    "df_train['question'] = df_train['question'].str.lower()\n",
    "df_train['answer_text'] = df_train['answer_text'].str.lower()\n",
    "df_train['distractor'] = df_train['distractor'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "HKysVLB1nMMc",
    "outputId": "314a752b-ec27-4359-fb76-3b1b64604956"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>distractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meals can be served</td>\n",
       "      <td>in rooms at 9:00 p. m.</td>\n",
       "      <td>'outside the room at 3:00 p. m.', 'in the dini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it can be inferred from the passage that</td>\n",
       "      <td>the local government can deal with the problem...</td>\n",
       "      <td>'if some tragedies occur again ', ' relevant d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the author called tommy 's parents in order to</td>\n",
       "      <td>help them realize their influence on tommy</td>\n",
       "      <td>'blame tommy for his failing grades', 'blame t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it can be inferred from the passage that</td>\n",
       "      <td>the writer is not very willing to use idioms</td>\n",
       "      <td>'idioms are the most important part in a langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how can we deal with snake wounds according to...</td>\n",
       "      <td>stay calm and do n't move .</td>\n",
       "      <td>'cut the wound and suck the poison out .'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  ...                                         distractor\n",
       "0                                meals can be served  ...  'outside the room at 3:00 p. m.', 'in the dini...\n",
       "1           it can be inferred from the passage that  ...  'if some tragedies occur again ', ' relevant d...\n",
       "2     the author called tommy 's parents in order to  ...  'blame tommy for his failing grades', 'blame t...\n",
       "3           it can be inferred from the passage that  ...  'idioms are the most important part in a langu...\n",
       "4  how can we deal with snake wounds according to...  ...          'cut the wound and suck the poison out .'\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmV9Bx3pnXPu"
   },
   "outputs": [],
   "source": [
    "df_test['question'] = df_test['question'].str.lower()\n",
    "df_test['answer_text'] = df_test['answer_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "LkrSnAPW34yQ",
    "outputId": "c92c158b-3cbb-4144-ad17-36023750ebc7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what 's the main idea of the text ?</td>\n",
       "      <td>the lack of career -- based courses in us high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in the summer high season , finland does nt se...</td>\n",
       "      <td>the sun is out at night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if you want to apply for chinese business inte...</td>\n",
       "      <td>have to get confirmed at least twice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that afternoon , the boy 's clothes were dry b...</td>\n",
       "      <td>nobody made room for him in the water .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which of the following statements is not true ?</td>\n",
       "      <td>there are twelve countries in the world wildli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question                                        answer_text\n",
       "0                what 's the main idea of the text ?  the lack of career -- based courses in us high...\n",
       "1  in the summer high season , finland does nt se...                            the sun is out at night\n",
       "2  if you want to apply for chinese business inte...               have to get confirmed at least twice\n",
       "3  that afternoon , the boy 's clothes were dry b...            nobody made room for him in the water .\n",
       "4    which of the following statements is not true ?  there are twelve countries in the world wildli..."
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "keuICtj1ttsp"
   },
   "source": [
    "**Converting the sentences given to list of words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJTPmDocoa6q"
   },
   "outputs": [],
   "source": [
    "# word_tokenize(df['question'][0])\n",
    "for x in range(len(df_train['question'])):\n",
    "    df_train['question'][x] = word_tokenize(df_train['question'][x])\n",
    "for y in range(len(df_train['answer_text'])):\n",
    "    df_train['answer_text'][y] = word_tokenize(df_train['answer_text'][y])\n",
    "for z in range(len(df_train['distractor'])):\n",
    "    df_train['distractor'][z] = word_tokenize(df_train['distractor'][z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "D_8hMdQ80fNU",
    "outputId": "67717a52-7439-41c7-886d-d871ded3a9e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>distractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[meals, can, be, served]</td>\n",
       "      <td>[in, rooms, at, 9:00, p., m, .]</td>\n",
       "      <td>['outside, the, room, at, 3:00, p., m., ', ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[it, can, be, inferred, from, the, passage, that]</td>\n",
       "      <td>[the, local, government, can, deal, with, the,...</td>\n",
       "      <td>['if, some, tragedies, occur, again, ', ,, ', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[the, author, called, tommy, 's, parents, in, ...</td>\n",
       "      <td>[help, them, realize, their, influence, on, to...</td>\n",
       "      <td>['blame, tommy, for, his, failing, grades, ', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[it, can, be, inferred, from, the, passage, that]</td>\n",
       "      <td>[the, writer, is, not, very, willing, to, use,...</td>\n",
       "      <td>['idioms, are, the, most, important, part, in,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[how, can, we, deal, with, snake, wounds, acco...</td>\n",
       "      <td>[stay, calm, and, do, n't, move, .]</td>\n",
       "      <td>['cut, the, wound, and, suck, the, poison, out...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  ...                                         distractor\n",
       "0                           [meals, can, be, served]  ...  ['outside, the, room, at, 3:00, p., m., ', ,, ...\n",
       "1  [it, can, be, inferred, from, the, passage, that]  ...  ['if, some, tragedies, occur, again, ', ,, ', ...\n",
       "2  [the, author, called, tommy, 's, parents, in, ...  ...  ['blame, tommy, for, his, failing, grades, ', ...\n",
       "3  [it, can, be, inferred, from, the, passage, that]  ...  ['idioms, are, the, most, important, part, in,...\n",
       "4  [how, can, we, deal, with, snake, wounds, acco...  ...  ['cut, the, wound, and, suck, the, poison, out...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNm-Irtk2n0A"
   },
   "outputs": [],
   "source": [
    "for x in range(len(df_test['question'])):\n",
    "    df_test['question'][x] = word_tokenize(df_test['question'][x])\n",
    "for y in range(len(df_test['answer_text'])):\n",
    "    df_test['answer_text'][y] = word_tokenize(df_test['answer_text'][y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "sh-Y5xX37Y15",
    "outputId": "3173e754-798d-44c0-bd4f-d2bbc8924f8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[what, 's, the, main, idea, of, the, text, ?]</td>\n",
       "      <td>[the, lack, of, career, --, based, courses, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[in, the, summer, high, season, ,, finland, do...</td>\n",
       "      <td>[the, sun, is, out, at, night]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[if, you, want, to, apply, for, chinese, busin...</td>\n",
       "      <td>[have, to, get, confirmed, at, least, twice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[that, afternoon, ,, the, boy, 's, clothes, we...</td>\n",
       "      <td>[nobody, made, room, for, him, in, the, water, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[which, of, the, following, statements, is, no...</td>\n",
       "      <td>[there, are, twelve, countries, in, the, world...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question                                        answer_text\n",
       "0      [what, 's, the, main, idea, of, the, text, ?]  [the, lack, of, career, --, based, courses, in...\n",
       "1  [in, the, summer, high, season, ,, finland, do...                     [the, sun, is, out, at, night]\n",
       "2  [if, you, want, to, apply, for, chinese, busin...       [have, to, get, confirmed, at, least, twice]\n",
       "3  [that, afternoon, ,, the, boy, 's, clothes, we...  [nobody, made, room, for, him, in, the, water, .]\n",
       "4  [which, of, the, following, statements, is, no...  [there, are, twelve, countries, in, the, world..."
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "luxBP_gCuB-w"
   },
   "source": [
    "**Removing stopwords from the dataset**\n",
    "\n",
    "Note:- stopwords are words those occur more frequently like is, the etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nK51DCoC9iCl"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NHulJY5K92t2"
   },
   "outputs": [],
   "source": [
    "for x in range(len(df_train['question'])):\n",
    "    df_train['question'][x] = [w for w in df_train['question'][x] if not w in stop_words]\n",
    "for y in range(len(df_train['answer_text'])):\n",
    "    df_train['answer_text'][y] = [w for w in df_train['answer_text'][y] if not w in stop_words]\n",
    "for z in range(len(df_train['distractor'])):\n",
    "    df_train['distractor'][z] = [w for w in df_train['distractor'][z] if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "zoJvTW4f-l3Q",
    "outputId": "4cbcf42e-b9d8-4488-f6f0-3eacf7cf0f8e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>distractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[meals, served]</td>\n",
       "      <td>[rooms, 9:00, p., .]</td>\n",
       "      <td>['outside, room, 3:00, p., m., ', ,, 'in, dini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[inferred, passage]</td>\n",
       "      <td>[local, government, deal, problem, lacking, mo...</td>\n",
       "      <td>['if, tragedies, occur, ', ,, ', relevant, dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[author, called, tommy, 's, parents, order]</td>\n",
       "      <td>[help, realize, influence, tommy]</td>\n",
       "      <td>['blame, tommy, failing, grades, ', ,, 'blame,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[inferred, passage]</td>\n",
       "      <td>[writer, willing, use, idioms]</td>\n",
       "      <td>['idioms, important, part, language, ', ,, 'no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[deal, snake, wounds, according, passage, ?]</td>\n",
       "      <td>[stay, calm, n't, move, .]</td>\n",
       "      <td>['cut, wound, suck, poison, ., ']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question  ...                                         distractor\n",
       "0                               [meals, served]  ...  ['outside, room, 3:00, p., m., ', ,, 'in, dini...\n",
       "1                           [inferred, passage]  ...  ['if, tragedies, occur, ', ,, ', relevant, dep...\n",
       "2   [author, called, tommy, 's, parents, order]  ...  ['blame, tommy, failing, grades, ', ,, 'blame,...\n",
       "3                           [inferred, passage]  ...  ['idioms, important, part, language, ', ,, 'no...\n",
       "4  [deal, snake, wounds, according, passage, ?]  ...                  ['cut, wound, suck, poison, ., ']\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lIf4-0mKuxAf"
   },
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsIaLDlPu1WF"
   },
   "source": [
    "Converting words to their root form. EXample: root form of **Playing** is **Play**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_x8vEZG_uN0"
   },
   "outputs": [],
   "source": [
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "# [WNlemma.lemmatize(t) for t in text7]\n",
    "for x in range(len(df_train['question'])):\n",
    "    df_train['question'][x] = [WNlemma.lemmatize(t) for t in df_train['question'][x]]\n",
    "for y in range(len(df_train['answer_text'])):\n",
    "    df_train['answer_text'][y] = [WNlemma.lemmatize(t) for t in df_train['answer_text'][y]]\n",
    "for z in range(len(df_train['distractor'])):\n",
    "    df_train['distractor'][z] = [WNlemma.lemmatize(t) for t in df_train['distractor'][z]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "_ZSsXy-aC1Sk",
    "outputId": "a2f89119-0661-49a6-b2f2-47208a5c0001"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>distractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[meal, served]</td>\n",
       "      <td>[room, 9:00, p., .]</td>\n",
       "      <td>['outside, room, 3:00, p., m., ', ,, 'in, dini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[inferred, passage]</td>\n",
       "      <td>[local, government, deal, problem, lacking, mo...</td>\n",
       "      <td>['if, tragedy, occur, ', ,, ', relevant, depar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[author, called, tommy, 's, parent, order]</td>\n",
       "      <td>[help, realize, influence, tommy]</td>\n",
       "      <td>['blame, tommy, failing, grade, ', ,, 'blame, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[inferred, passage]</td>\n",
       "      <td>[writer, willing, use, idiom]</td>\n",
       "      <td>['idioms, important, part, language, ', ,, 'no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[deal, snake, wound, according, passage, ?]</td>\n",
       "      <td>[stay, calm, n't, move, .]</td>\n",
       "      <td>['cut, wound, suck, poison, ., ']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      question  ...                                         distractor\n",
       "0                               [meal, served]  ...  ['outside, room, 3:00, p., m., ', ,, 'in, dini...\n",
       "1                          [inferred, passage]  ...  ['if, tragedy, occur, ', ,, ', relevant, depar...\n",
       "2   [author, called, tommy, 's, parent, order]  ...  ['blame, tommy, failing, grade, ', ,, 'blame, ...\n",
       "3                          [inferred, passage]  ...  ['idioms, important, part, language, ', ,, 'no...\n",
       "4  [deal, snake, wound, according, passage, ?]  ...                  ['cut, wound, suck, poison, ., ']\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqhgGGGbDHaO"
   },
   "outputs": [],
   "source": [
    "for x in range(len(df_train['question'])):\n",
    "    df_train['question'][x] = [re.sub(r\"[^a-zA-Z0-9]+\", '', k) for k in df_train['question'][x]]\n",
    "for y in range(len(df_train['answer_text'])):\n",
    "    df_train['answer_text'][y] = [re.sub(r\"[^a-zA-Z0-9]+\", '', k) for k in df_train['answer_text'][y]]\n",
    "for z in range(len(df_train['distractor'])):\n",
    "        df_train['distractor'][z] = [re.sub(r\"[^a-zA-Z0-9]+\", '', k) for k in df_train['distractor'][z]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "Ctfq3GFCFsvE",
    "outputId": "f0b4e590-0ca7-4b60-b689-b63dd5a78943"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>distractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[meal, served]</td>\n",
       "      <td>[room, 900, p, ]</td>\n",
       "      <td>[outside, room, 300, p, m, , , in, dining, , r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[inferred, passage]</td>\n",
       "      <td>[local, government, deal, problem, lacking, mo...</td>\n",
       "      <td>[if, tragedy, occur, , , , relevant, departmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[author, called, tommy, s, parent, order]</td>\n",
       "      <td>[help, realize, influence, tommy]</td>\n",
       "      <td>[blame, tommy, failing, grade, , , blame, tomm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[inferred, passage]</td>\n",
       "      <td>[writer, willing, use, idiom]</td>\n",
       "      <td>[idioms, important, part, language, , , nonnat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[deal, snake, wound, according, passage, ]</td>\n",
       "      <td>[stay, calm, nt, move, ]</td>\n",
       "      <td>[cut, wound, suck, poison, , ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     question  ...                                         distractor\n",
       "0                              [meal, served]  ...  [outside, room, 300, p, m, , , in, dining, , r...\n",
       "1                         [inferred, passage]  ...  [if, tragedy, occur, , , , relevant, departmen...\n",
       "2   [author, called, tommy, s, parent, order]  ...  [blame, tommy, failing, grade, , , blame, tomm...\n",
       "3                         [inferred, passage]  ...  [idioms, important, part, language, , , nonnat...\n",
       "4  [deal, snake, wound, according, passage, ]  ...                     [cut, wound, suck, poison, , ]\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hGNFtAnbKEL4"
   },
   "outputs": [],
   "source": [
    "lw = []\n",
    "for i in range(len(df_train['question'])):\n",
    "    for w in df_train['question'][i]:\n",
    "        if len(w)>1:\n",
    "            lw.append(w)\n",
    "            \n",
    "for i in range(len(df_train['answer_text'])):\n",
    "    for w in df_train['answer_text'][i]:\n",
    "        if len(w)>1:\n",
    "            lw.append(w)\n",
    "            \n",
    "for i in range(len(df_train['distractor'])):\n",
    "    for w in df_train['distractor'][i]:\n",
    "        if len(w)>1:\n",
    "            lw.append(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UTlNmuBT9AGZ"
   },
   "source": [
    "# Processing Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hp8WThd-2zlm"
   },
   "outputs": [],
   "source": [
    "# word_tokenize(df['question'][0])\n",
    "for x in range(len(df_test['question'])):\n",
    "    df_test['question'][x] = [w for w in df_test['question'][x] if not w in stop_words]\n",
    "for y in range(len(df_test['answer_text'])):\n",
    "    df_test['answer_text'][y] = [w for w in df_test['answer_text'][y] if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJMPNXCL5JY6"
   },
   "outputs": [],
   "source": [
    "# WNlemma = nltk.WordNetLemmatizer()\n",
    "# [WNlemma.lemmatize(t) for t in text7]\n",
    "for x in range(len(df_test['question'])):\n",
    "    df_test['question'][x] = [WNlemma.lemmatize(t) for t in df_test['question'][x]]\n",
    "for y in range(len(df_test['answer_text'])):\n",
    "    df_test['answer_text'][y] = [WNlemma.lemmatize(t) for t in df_test['answer_text'][y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nhXbItat53ka"
   },
   "outputs": [],
   "source": [
    "for x in range(len(df_test['question'])):\n",
    "    df_test['question'][x] = [re.sub(r\"[^a-zA-Z0-9]+\", '', k) for k in df_test['question'][x]]\n",
    "for y in range(len(df_test['answer_text'])):\n",
    "    df_test['answer_text'][y] = [re.sub(r\"[^a-zA-Z0-9]+\", '', k) for k in df_test['answer_text'][y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pQ8RjU8V6QFr"
   },
   "outputs": [],
   "source": [
    "test_list = []\n",
    "for i in range(len(df_test['question'])):\n",
    "    for w in df_test['question'][i]:\n",
    "        if len(w)>1:\n",
    "            test_list.append(w) \n",
    "            \n",
    "for i in range(len(df_test['answer_text'])):\n",
    "    for w in df_test['answer_text'][i]:\n",
    "        if len(w)>1:\n",
    "            test_list.append(w) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n5XmmTsr8oIM"
   },
   "source": [
    "# Training Model\n",
    "Preparing list of all words to train them using word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Activation,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.objectives import cosine_proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2vec = FastText(size=4, window=5, min_count=0)  # instantiate\n",
    "model_2vec.build_vocab(sentences=[corpus])\n",
    "model_2vec.train(sentences=[corpus], total_examples=len(corpus), epochs=10) \n",
    "\n",
    "sequences = list()\n",
    "for i in range(1, len(corpus)):\n",
    "    sequence = corpus[i-1:i+1]\n",
    "    sequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "\n",
    "vocab_size,emdedding_size,pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_len = 10\n",
    "pretrained_weights = model_2vec.wv.syn0\n",
    "vocab_size, emdedding_size = pretrained_weights.shape\n",
    "def idx2word(idx):\n",
    "    return model_2vec.wv.index2word[idx]\n",
    "\n",
    "def word2idx(word):\n",
    "    return model_2vec.wv.vocab[word].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nPreparing the data for LSTM...')\n",
    "train_x = np.zeros([len(sequences), 23440], dtype=np.int32)\n",
    "train_y = np.zeros([len(sequences), 23440], dtype=np.int32)\n",
    "for i in range(len(sequences)):\n",
    "    train_x[i] = word2idx(sequences[i][0])\n",
    "    train_y[i] = word2idx(sequences[i][1])\n",
    "print('train_x shape:', train_x.shape)\n",
    "print('train_y shape:', train_y.shape)\n",
    "\n",
    "train_x=train_x/23332\n",
    "train_y=train_y/23332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Defining a Simple Keras Model...')\n",
    "model=Sequential()  \n",
    "model.add(Embedding(input_dim=model_2vec.wv.syn0.shape[0],output_dim=model_2vec.wv.syn0.shape[1],weights=[model_2vec.wv.syn0])) \n",
    "model.add(LSTM(units=500))\n",
    "\n",
    "model.add(Dense(23440, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ucKDHlVGz-AC",
    "outputId": "dad72c99-6be8-4313-b28d-b98049edbd5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "603161"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='cosine_proximity',metrics=['accuracy'])\n",
    "model.fit(train_x ,train_y,epochs=1,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    if temperature <= 0:\n",
    "        return np.argmax(preds)\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate_next(text):\n",
    "    \n",
    "    word_idxs = [word2idx(word) for word in text.lower().split()]\n",
    "    \n",
    "    for i in range(10):\n",
    "        prediction = model.predict(x=np.array(word_idxs))\n",
    "        \n",
    "        idx = sample(prediction[-1], temperature=0.6)\n",
    "        \n",
    "        word_idxs.append(idx)\n",
    "        l.append(' '.join(idx2word(idx) for idx in word_idxs))\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3bfHbhv9RCW"
   },
   "source": [
    "# Generating distractor \n",
    "for the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mo6_C_r_KUg3"
   },
   "source": [
    "**Distractor 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "DjpIC8047m7o",
    "outputId": "bfe0bcc7-a142-42dc-e221-d810b4e7bb65"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "dist = []\n",
    "for i in range(len(df_test['answer_text'])):\n",
    "    ls = []\n",
    "    for w in df_test['answer_text'][i]:\n",
    "    if(len(w)>1):\n",
    "        ls.append(generate_next(w)[0][0])\n",
    "    dist.append(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdbJ2UcOyOWv"
   },
   "outputs": [],
   "source": [
    "distractor = []\n",
    "for j in range(len(dist)):\n",
    "    Str = ' '.join([str(elem) for elem in dist[j]])\n",
    "    distractor.append(Str);\n",
    "\n",
    "#checking distractors generated\n",
    "distractor[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCK0ocxsKaEa"
   },
   "source": [
    "**Distractor 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "5_voS7Sf13kW",
    "outputId": "4871845a-a80e-46b2-d432-eeef7e29f7e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "dist1 = []\n",
    "for i in range(len(df_test['answer_text'])):\n",
    "    ls = []\n",
    "    for w in df_test['answer_text'][i]:\n",
    "    if(len(w)>1):\n",
    "        ls.append(model_test.most_similar(w)[1][0])\n",
    "    dist1.append(ls)\n",
    "distractor1 = []\n",
    "for j in range(len(dist1)):\n",
    "    Str = ' '.join([str(elem) for elem in dist1[j]])\n",
    "    distractor1.append(Str);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "hrPEJBf3LwhH",
    "outputId": "a46a7935-4d9c-4f73-f1dc-841221fbf56c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13500\n",
      "['monday conclude go may idea writer', 'toast could', 'writer introduces wrote mutate', 'mothered purpose tell story', 'childhood man author exam guimi', 'text want mainly choose eyed cartoons', 'ravaged purpose ios dar counsellor', 'chiver unconscious used writer subsidize', 'muybridge infer windsurfer story title', 'want noun future way', 'leech newsagent tell', 'think directly mainly girl seaside', 'glasses hillsborough', 'clawing kensington marwick', 'passage calgary parent mean action parent', 'title statement article driver', 'splendidly person', 'learn porsche tubby probably', 'notable passage article', 'teensgiving asean prevention chuanzhusi', 'want bette terrifying inferred', 'title following ftc borough beginner said', 'sinar 888', 'birdcage according scientist want according according', 'mentioned charge local reporting']\n"
     ]
    }
   ],
   "source": [
    "print(len(distractor1))\n",
    "print(distractor1[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5cFztYRKd0S"
   },
   "source": [
    "**Distractor 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "gqNzaj8z_C-r",
    "outputId": "d2866752-a7b8-4d30-9620-4b8ab665f0c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "dist2 = []\n",
    "for i in range(len(df_test['answer_text'])):\n",
    "    ls = []\n",
    "    for w in df_test['answer_text'][i]:\n",
    "    if(len(w)>1):\n",
    "        ls.append(model_test.most_similar(w)[2][0])\n",
    "    dist2.append(ls)\n",
    "distractor2 = []\n",
    "for j in range(len(dist1)):\n",
    "    Str = ' '.join([str(elem) for elem in dist2[j]])\n",
    "    distractor2.append(Str);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "g2A5bk5VADll",
    "outputId": "1290ca81-d2ea-4597-f1d5-f41f35cb178b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13500\n",
      "['spell mention team forest many mainly', 'formative order', 'according embryo important 10732', 'competence idea father inferred', 'clements new writer information morrison', 'according think purpose wrong creaking jiansong', 'lassen idea aibo 2300 westminster', 'urgent conclude title following dissolving', 'hugeness writer dunant would tell', 'think soup club advised', 'o2 misled infer', 'statement information following take leaders', 'fes moneyball', 'rubber laver concerned', 'following bun father might estate father', 'tell following statement sentence', 'attained dream', 'true ruled inicates author', 'calling story tell', '1830s stop discussing secondly', 'think cheese terminator article', 'tell passage nosed smugglers mulch rule', 'fluid symbolic', 'hands statement research think statement learn', 'article digitalkidsworld usstudent 19thand']\n"
     ]
    }
   ],
   "source": [
    "print(len(distractor2))\n",
    "print(distractor2[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQKNFVr4AVi4"
   },
   "outputs": [],
   "source": [
    "final_distractor = []\n",
    "for i in range(13500):\n",
    "    ls = []\n",
    "    ls.append(distractor[i])\n",
    "    ls.append(distractor1[i])\n",
    "    ls.append(distractor2[i])\n",
    "#   print(ls)\n",
    "    final_distractor.append(ls)\n",
    "# print(final_distractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8-aLvAUgKryK"
   },
   "source": [
    "**Joining all three distractors by comma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1pkFMHSEBs59"
   },
   "outputs": [],
   "source": [
    "dist_list = []\n",
    "for k in range(len(final_distractor)):\n",
    "    string = '\\',\\''.join(str(element) for element in final_distractor[k])\n",
    "    dist_list.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJL0SjhWBvWT"
   },
   "outputs": [],
   "source": [
    "for elem in dist_list:\n",
    "    if elem =='':\n",
    "        elem = 'hello'#dist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xQ2hTJobE-3j",
    "outputId": "8c2dcd10-c263-4b77-f823-a1cca23e4dc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1368 showed way thing need story','monday conclude go may idea writer','spell mention team forest many mainly\""
      ]
     },
     "execution_count": 173,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WsOtlgY0Ki-6"
   },
   "source": [
    "**converting Distractor to data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ghwq4oECZgF"
   },
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame(dist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "0YkcJkAVFG8e",
    "outputId": "6cff58b7-df7d-4b7a-eea0-64946c07f5fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1368 showed way thing need story','monday conc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attraeted like','toast could','formative order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>author scholastic chinese patiently','writer i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1926 infer take first','mothered purpose tell ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>producers need true driver inattentively','chi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  1368 showed way thing need story','monday conc...\n",
       "1     attraeted like','toast could','formative order\n",
       "2  author scholastic chinese patiently','writer i...\n",
       "3  1926 infer take first','mothered purpose tell ...\n",
       "4  producers need true driver inattentively','chi..."
      ]
     },
     "execution_count": 175,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLCR0e0VEaKT"
   },
   "outputs": [],
   "source": [
    "data_frame.to_csv('f_dist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oO65C1BREsyY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "distractor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
